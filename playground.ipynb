{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CA RNN\n",
    "Toy example in 1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Example\n",
    "'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from train import train\n",
    "\n",
    "\n",
    "class ExtendedGRUcell(tf.contrib.rnn.GRUCell):\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        new_h, new_h = super().__call__(inputs, state, scope=None)\n",
    "        \n",
    "        print('extending')\n",
    "        \n",
    "        return new_h, new_h\n",
    "        \n",
    "        \n",
    "class Model(object):\n",
    "    def __init__(self, \n",
    "                 batch_size, \n",
    "                 state_size,\n",
    "                 num_classes,\n",
    "                 rnn_size,\n",
    "                 learning_rate,\n",
    "                 cell_name):\n",
    "        self._cell_name = cell_name\n",
    "        self._batch_size = batch_size\n",
    "        self._state_size = state_size\n",
    "        self._num_classes = num_classes\n",
    "        self._rnn_size = rnn_size\n",
    "        self._lr = learning_rate\n",
    "        \n",
    "        self._create_inference()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "        self._create_prediction()\n",
    "    \n",
    "    @property\n",
    "    def inference(self):\n",
    "        return self._inference\n",
    "        \n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self._loss\n",
    "    \n",
    "    @property\n",
    "    def optimizer(self):\n",
    "        return self._optimizer\n",
    "        \n",
    "    @property\n",
    "    def prediction(self):\n",
    "        return self._prediction\n",
    "    \n",
    "    def _create_inference(self):\n",
    "        with tf.name_scope('inference'):\n",
    "            width = 5\n",
    "            height = 1\n",
    "            depth = 1\n",
    "            classes = 2\n",
    "\n",
    "            # cell selection\n",
    "            additional_cell_args = {}\n",
    "            if self._cell_name == 'lstm':\n",
    "                cell_fn = tf.contrib.rnn.LSTMCell\n",
    "            elif self._cell_name == 'grid1lstm':\n",
    "                cell_fn = tf.contrib.grid_rnn.Grid1LSTMCell\n",
    "#                 additional_cell_args.update({'state_is_tuple': True})\n",
    "            elif self._cell_name == 'grid2lstm':\n",
    "                cell_fn = tf.contrib.grid_rnn.Grid2LSTMCell\n",
    "            elif self._cell_name == 'tf-gridlstm':\n",
    "                cell_fn = tf.contrib.rnn.GridLSTMCell\n",
    "                additional_cell_args.update({'state_is_tuple': True, 'num_frequency_blocks': [1]})\n",
    "            else:\n",
    "                raise Exception('Unsupported cell_name: {}'.format(self._cell_name))\n",
    "            \n",
    "            cell = cell_fn(num_units=self._state_size, **additional_cell_args)\n",
    "\n",
    "            # inputs\n",
    "            self._input_data, self._targets = self._input_pipeline()\n",
    "            initial_state = cell.zero_state(self._batch_size, tf.float32)  # possibly x\n",
    "            \n",
    "            # rnn\n",
    "            with tf.variable_scope('rnn'):\n",
    "                softmax_w = tf.get_variable('softmax_w', [self._rnn_size * self._state_size, self._num_classes]) \n",
    "                softmax_b = tf.get_variable('softmax_b', [self._num_classes])\n",
    "                with tf.device('/cpu:0'):\n",
    "                    inputs = tf.reshape(self._input_data, [self._batch_size, self._rnn_size, 1])\n",
    "                    inputs = tf.unstack(inputs, axis=1)\n",
    "                    # print('DEBUG: ', inputs[0].get_shape())\n",
    "\n",
    "                # inputs: A length T list of inputs, each a Tensor of shape [batch_size, input_size]\n",
    "                outputs, final_state = tf.contrib.rnn.static_rnn(cell, inputs, initial_state=initial_state)\n",
    "\n",
    "            with tf.name_scope('softmax'):\n",
    "                output = tf.concat(outputs, 1)\n",
    "                self._logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "        \n",
    "    def _create_loss(self):\n",
    "        # loss function\n",
    "        with tf.name_scope('loss'):\n",
    "            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=self._logits, labels=self._targets, name='cross_entropy')\n",
    "            self._loss = tf.reduce_mean(cross_entropy)\n",
    "            \n",
    "    def _create_optimizer(self):\n",
    "        # optimizer\n",
    "            self._optimizer = tf.train.AdamOptimizer(self._lr).minimize(self._loss)\n",
    "            \n",
    "    def _create_prediction(self):\n",
    "        # evaluation\n",
    "        with tf.name_scope('prediction'):\n",
    "            correct = tf.nn.in_top_k(self._logits, self._targets, 1)\n",
    "            self._prediction = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "    def _input_pipeline(self):\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            ['data/const_train_1_200000x5x1x1.tfrecords',\n",
    "             'data/const_train_2_200000x5x1x1.tfrecords'], num_epochs=None)\n",
    "\n",
    "        def read_and_decode(filename_queue):\n",
    "            # read\n",
    "            reader = tf.TFRecordReader()\n",
    "            _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "            feature_map = {\n",
    "                'x': tf.FixedLenFeature(\n",
    "                    shape=[], dtype=tf.string),\n",
    "                'y': tf.FixedLenFeature(\n",
    "                    shape=[], dtype=tf.int64,\n",
    "                    default_value=None)\n",
    "            }\n",
    "            parsed = tf.parse_single_example(serialized_example, feature_map)\n",
    "\n",
    "            # decode\n",
    "            width = 5\n",
    "            height = 1\n",
    "            depth = 1\n",
    "\n",
    "            features = tf.decode_raw(parsed['x'], tf.int64)\n",
    "            features = tf.reshape(features, [width, height, depth])\n",
    "            features = tf.cast(features, dtype=tf.float32)\n",
    "            labels = parsed['y']\n",
    "\n",
    "            return features, labels\n",
    "\n",
    "        features, labels = read_and_decode(filename_queue)\n",
    "\n",
    "        min_after_dequeue = 5000\n",
    "        capacity = min_after_dequeue + 3 + self._batch_size\n",
    "        example_batch, label_batch = tf.train.shuffle_batch(\n",
    "            [features, labels], \n",
    "            batch_size=self._batch_size, \n",
    "            capacity=capacity,\n",
    "            num_threads=4,\n",
    "            allow_smaller_final_batch=False,\n",
    "            min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "        return example_batch, label_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x104794828>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.LSTMCell object at 0x104794828>: The input_size parameter is deprecated.\n",
      "############### Training ###############\n",
      "steps: 100 num_examples: 12,800 average_loss: 0.2303\n",
      "steps: 200 num_examples: 25,600 average_loss: 0.1167\n",
      "steps: 300 num_examples: 38,400 average_loss: 0.07813\n",
      "steps: 400 num_examples: 51,200 average_loss: 0.05873\n",
      "steps: 500 num_examples: 64,000 average_loss: 0.04705\n",
      "steps: 600 num_examples: 76,800 average_loss: 0.03925\n",
      "steps: 700 num_examples: 89,600 average_loss: 0.03367\n",
      "steps: 800 num_examples: 102,400 average_loss: 0.02947\n",
      "steps: 900 num_examples: 115,200 average_loss: 0.02621\n",
      "steps: 1000 num_examples: 128,000 average_loss: 0.0236\n",
      "############### Finished ###############\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-625d8decaebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m               cell_name)\n\u001b[1;32m     16\u001b[0m train(model,\n\u001b[0;32m---> 17\u001b[0;31m       batch_size)\n\u001b[0m",
      "\u001b[0;32m/Users/fred/Developer/ca-rnn/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fred/Developer/ca-rnn/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fred/Developer/ca-rnn/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fred/Developer/ca-rnn/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/fred/Developer/ca-rnn/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fred/Developer/ca-rnn/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "batch_size = 128\n",
    "state_size = 6\n",
    "num_classes = 2\n",
    "rnn_size = 5\n",
    "learning_rate = 0.01\n",
    "epochs = None;\n",
    "cell_name = 'grid2lstm'\n",
    "\n",
    "model = Model(batch_size, \n",
    "              state_size,\n",
    "              num_classes,\n",
    "              rnn_size,\n",
    "              learning_rate,\n",
    "              cell_name)\n",
    "train(model,\n",
    "      batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
